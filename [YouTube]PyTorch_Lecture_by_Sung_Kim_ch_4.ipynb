{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[YouTube]PyTorch_Lecture_by_Sung_Kim_ch_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNV4rMyrCHHr0OyZ2nPxfQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mori8/NLP-Pytorch-practice/blob/main/%5BYouTube%5DPyTorch_Lecture_by_Sung_Kim_ch_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2MZNLymm23V"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "x_data = [1.0, 2.0, 3.0]\n",
        "y_data = [2.0, 4.0, 6.0]\n",
        "\n",
        "w = Variable(torch.Tensor([1.0]), requires_grad=True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O2NpqL3nIj0"
      },
      "source": [
        "def forward(x):\n",
        "  return x * w\n",
        "\n",
        "def loss(x, y):\n",
        "  y_pred = forward(x)\n",
        "  return (y_pred - y) * (y_pred - y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8fVhAAQnViM",
        "outputId": "770fe1b2-9414-4bc7-f6dc-42861229be06"
      },
      "source": [
        "for epoch in range(10):\n",
        "  for x_val, y_val in zip(x_data, y_data):\n",
        "    l = loss(x_val, y_val)\n",
        "    l.backward()\n",
        "    print(\"\\tgrad:\", x_val, y_val, w.grad.data[0])\n",
        "    w.data = w.data - 0.01 * w.grad.data # w.grad.data = d_loss / d_w\n",
        "    # Manually zero the gradients after updating weights\n",
        "    w.grad.data.zero_()\n",
        "  print(\"progress:\", epoch, l.data[0])\n",
        "\n",
        "print(\"predict (after training)\", 4, forward(4).data[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tgrad: 1.0 2.0 tensor(-0.0048)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0187)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0386)\n",
            "progress: 0 tensor(4.1433e-05)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0035)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0138)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0286)\n",
            "progress: 1 tensor(2.2647e-05)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0026)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0102)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0211)\n",
            "progress: 2 tensor(1.2377e-05)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0019)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0075)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0156)\n",
            "progress: 3 tensor(6.7684e-06)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0014)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0056)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0115)\n",
            "progress: 4 tensor(3.7001e-06)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0011)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0041)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0085)\n",
            "progress: 5 tensor(2.0219e-06)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0008)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0030)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0063)\n",
            "progress: 6 tensor(1.1045e-06)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0006)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0023)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0047)\n",
            "progress: 7 tensor(6.0411e-07)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0004)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0017)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0034)\n",
            "progress: 8 tensor(3.2960e-07)\n",
            "\tgrad: 1.0 2.0 tensor(-0.0003)\n",
            "\tgrad: 2.0 4.0 tensor(-0.0012)\n",
            "\tgrad: 3.0 6.0 tensor(-0.0025)\n",
            "progress: 9 tensor(1.8051e-07)\n",
            "predict (after training) 4 tensor(7.9995)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic9kM_ero5I6"
      },
      "source": [
        "# Exercise 4-3: implement computational graph and backprop using Numpy or just a pure Python\n",
        "\n",
        "w1 = 1.0\n",
        "l = 0\n",
        "\n",
        "def my_forward(x):\n",
        "  return x * w1\n",
        "\n",
        "def my_loss(x, y):\n",
        "  y_pred = my_forward(x)\n",
        "  return (y_pred - y) * (y_pred - y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HDa0UkIywYS",
        "outputId": "990d392b-bcad-4678-b258-1d8a1e2faec1"
      },
      "source": [
        "print(\"predict (before training)\", 4, my_forward(4))\n",
        "for epoch in range(100):\n",
        "  for x_val, y_val in zip(x_data, y_data):\n",
        "    d1 = x_val\n",
        "    d2 = 1\n",
        "    d3 = (my_forward(x_val) - y_val) * 2\n",
        "    grad = d1 * d2 * d3\n",
        "    print(\"\\tgrad:\", x_val, y_val, grad)\n",
        "    w1 = w1 - 0.01 * grad\n",
        "    l = my_loss(x_val, y_val)\n",
        "  print(\"progress:\", epoch, \"w =\", w, \"loss =\", l)\n",
        "\n",
        "print(\"predict (after training)\", \"4\", my_forward(4))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict (before training) 4 4.4445359959302765e-281\n",
            "\tgrad: 1.0 2.0 -4.0\n",
            "\tgrad: 2.0 4.0 -15.68\n",
            "\tgrad: 3.0 6.0 -32.4576\n",
            "progress: 0 w = tensor([1.9999], requires_grad=True) loss = 19.676960400383997\n",
            "\tgrad: 1.0 2.0 -2.957248\n",
            "\tgrad: 2.0 4.0 -11.59241216\n",
            "\tgrad: 3.0 6.0 -23.9962931712\n",
            "progress: 1 w = tensor([1.9999], requires_grad=True) loss = 10.755076961063336\n",
            "\tgrad: 1.0 2.0 -2.186328933376\n",
            "\tgrad: 2.0 4.0 -8.57040941883392\n",
            "\tgrad: 3.0 6.0 -17.740747496986216\n",
            "progress: 2 w = tensor([1.9999], requires_grad=True) loss = 5.878533985164598\n",
            "\tgrad: 1.0 2.0 -1.6163792163920774\n",
            "\tgrad: 2.0 4.0 -6.336206528256943\n",
            "\tgrad: 3.0 6.0 -13.115947513491871\n",
            "progress: 3 w = tensor([1.9999], requires_grad=True) loss = 3.2131022343998694\n",
            "\tgrad: 1.0 2.0 -1.1950085512292592\n",
            "\tgrad: 2.0 4.0 -4.684433520818697\n",
            "\tgrad: 3.0 6.0 -9.696777388094706\n",
            "progress: 4 w = tensor([1.9999], requires_grad=True) loss = 1.7562245952408784\n",
            "\tgrad: 1.0 2.0 -0.8834841620264062\n",
            "\tgrad: 2.0 4.0 -3.4632579151435117\n",
            "\tgrad: 3.0 6.0 -7.168943884347071\n",
            "progress: 5 w = tensor([1.9999], requires_grad=True) loss = 0.9599211615204214\n",
            "\tgrad: 1.0 2.0 -0.6531704427960663\n",
            "\tgrad: 2.0 4.0 -2.5604281357605796\n",
            "\tgrad: 3.0 6.0 -5.300086241024399\n",
            "progress: 6 w = tensor([1.9999], requires_grad=True) loss = 0.5246758522979971\n",
            "\tgrad: 1.0 2.0 -0.48289674640444513\n",
            "\tgrad: 2.0 4.0 -1.8929552459054246\n",
            "\tgrad: 3.0 6.0 -3.918417359024229\n",
            "progress: 7 w = tensor([1.9999], requires_grad=True) loss = 0.2867784991307062\n",
            "\tgrad: 1.0 2.0 -0.35701135937776307\n",
            "\tgrad: 2.0 4.0 -1.3994845287608317\n",
            "\tgrad: 3.0 6.0 -2.89693297453492\n",
            "progress: 8 w = tensor([1.9999], requires_grad=True) loss = 0.1567480325299015\n",
            "\tgrad: 1.0 2.0 -0.26394278212429256\n",
            "\tgrad: 2.0 4.0 -1.0346557059272268\n",
            "\tgrad: 3.0 6.0 -2.1417373112693614\n",
            "progress: 9 w = tensor([1.9999], requires_grad=True) loss = 0.08567568969247134\n",
            "\tgrad: 1.0 2.0 -0.19513606613787493\n",
            "\tgrad: 2.0 4.0 -0.7649333792604693\n",
            "\tgrad: 3.0 6.0 -1.583412095069173\n",
            "progress: 10 w = tensor([1.9999], requires_grad=True) loss = 0.04682880981539823\n",
            "\tgrad: 1.0 2.0 -0.14426643532852435\n",
            "\tgrad: 2.0 4.0 -0.5655244264878156\n",
            "\tgrad: 3.0 6.0 -1.17063556282978\n",
            "progress: 11 w = tensor([1.9999], requires_grad=True) loss = 0.025595795453742087\n",
            "\tgrad: 1.0 2.0 -0.10665790683560239\n",
            "\tgrad: 2.0 4.0 -0.418098994795562\n",
            "\tgrad: 3.0 6.0 -0.8654649192268096\n",
            "progress: 12 w = tensor([1.9999], requires_grad=True) loss = 0.013990207043322624\n",
            "\tgrad: 1.0 2.0 -0.07885347041844293\n",
            "\tgrad: 2.0 4.0 -0.30910560404029574\n",
            "\tgrad: 3.0 6.0 -0.6398486003634112\n",
            "progress: 13 w = tensor([1.9999], requires_grad=True) loss = 0.007646798610684228\n",
            "\tgrad: 1.0 2.0 -0.0582973169219998\n",
            "\tgrad: 2.0 4.0 -0.22852548233423953\n",
            "\tgrad: 3.0 6.0 -0.4730477484318776\n",
            "progress: 14 w = tensor([1.9999], requires_grad=True) loss = 0.004179604262559594\n",
            "\tgrad: 1.0 2.0 -0.04309990596823754\n",
            "\tgrad: 2.0 4.0 -0.1689516313954904\n",
            "\tgrad: 3.0 6.0 -0.3497298769886612\n",
            "progress: 15 w = tensor([1.9999], requires_grad=True) loss = 0.0022844974323238784\n",
            "\tgrad: 1.0 2.0 -0.03186427768118927\n",
            "\tgrad: 2.0 4.0 -0.12490796851026253\n",
            "\tgrad: 3.0 6.0 -0.2585594948162431\n",
            "progress: 16 w = tensor([1.9999], requires_grad=True) loss = 0.0012486657086282485\n",
            "\tgrad: 1.0 2.0 -0.023557642861035788\n",
            "\tgrad: 2.0 4.0 -0.09234596001526008\n",
            "\tgrad: 3.0 6.0 -0.19115613723159086\n",
            "progress: 17 w = tensor([1.9999], requires_grad=True) loss = 0.0006824984917220796\n",
            "\tgrad: 1.0 2.0 -0.017416448058877876\n",
            "\tgrad: 2.0 4.0 -0.06827247639080092\n",
            "\tgrad: 3.0 6.0 -0.14132402612895945\n",
            "progress: 18 w = tensor([1.9999], requires_grad=True) loss = 0.0003730415498593563\n",
            "\tgrad: 1.0 2.0 -0.012876189047304809\n",
            "\tgrad: 2.0 4.0 -0.050474661065434745\n",
            "\tgrad: 3.0 6.0 -0.10448254840545168\n",
            "progress: 19 w = tensor([1.9999], requires_grad=True) loss = 0.00020389788345224403\n",
            "\tgrad: 1.0 2.0 -0.009519521076941206\n",
            "\tgrad: 2.0 4.0 -0.03731652262160878\n",
            "\tgrad: 3.0 6.0 -0.07724520182673444\n",
            "progress: 20 w = tensor([1.9999], requires_grad=True) loss = 0.00011144696051144279\n",
            "\tgrad: 1.0 2.0 -0.0070378961664356865\n",
            "\tgrad: 2.0 4.0 -0.02758855297242846\n",
            "\tgrad: 3.0 6.0 -0.05710830465292638\n",
            "progress: 21 w = tensor([1.9999], requires_grad=True) loss = 6.091492857574774e-05\n",
            "\tgrad: 1.0 2.0 -0.005203201090600018\n",
            "\tgrad: 2.0 4.0 -0.02039654827515136\n",
            "\tgrad: 3.0 6.0 -0.042220854929563956\n",
            "progress: 22 w = tensor([1.9999], requires_grad=True) loss = 3.3295017704924826e-05\n",
            "\tgrad: 1.0 2.0 -0.003846789004693818\n",
            "\tgrad: 2.0 4.0 -0.01507941289839998\n",
            "\tgrad: 3.0 6.0 -0.03121438469968929\n",
            "progress: 23 w = tensor([1.9999], requires_grad=True) loss = 1.819846513638714e-05\n",
            "\tgrad: 1.0 2.0 -0.0028439772726382984\n",
            "\tgrad: 2.0 4.0 -0.0111483909087422\n",
            "\tgrad: 3.0 6.0 -0.023077169181094703\n",
            "progress: 24 w = tensor([1.9999], requires_grad=True) loss = 9.946957717681357e-06\n",
            "\tgrad: 1.0 2.0 -0.002102586525388972\n",
            "\tgrad: 2.0 4.0 -0.008242139179523988\n",
            "\tgrad: 3.0 6.0 -0.017061228101617587\n",
            "progress: 25 w = tensor([1.9999], requires_grad=True) loss = 5.4368303643092846e-06\n",
            "\tgrad: 1.0 2.0 -0.0015544674492584676\n",
            "\tgrad: 2.0 4.0 -0.0060935124010939035\n",
            "\tgrad: 3.0 6.0 -0.012613570670264806\n",
            "progress: 26 w = tensor([1.9999], requires_grad=True) loss = 2.971674882837903e-06\n",
            "\tgrad: 1.0 2.0 -0.0011492364388465681\n",
            "\tgrad: 2.0 4.0 -0.004505006840279435\n",
            "\tgrad: 3.0 6.0 -0.009325364159380456\n",
            "progress: 27 w = tensor([1.9999], requires_grad=True) loss = 1.6242646942346695e-06\n",
            "\tgrad: 1.0 2.0 -0.0008496442900765011\n",
            "\tgrad: 2.0 4.0 -0.0033306056170996357\n",
            "\tgrad: 3.0 6.0 -0.006894353627398431\n",
            "progress: 28 w = tensor([1.9999], requires_grad=True) loss = 8.877942241164479e-07\n",
            "\tgrad: 1.0 2.0 -0.0006281522193849476\n",
            "\tgrad: 2.0 4.0 -0.0024623566999881774\n",
            "\tgrad: 3.0 6.0 -0.005097078368976327\n",
            "progress: 29 w = tensor([1.9999], requires_grad=True) loss = 4.852525497670732e-07\n",
            "\tgrad: 1.0 2.0 -0.0004644004736178431\n",
            "\tgrad: 2.0 4.0 -0.0018204498565825844\n",
            "\tgrad: 3.0 6.0 -0.003768331203122699\n",
            "progress: 30 w = tensor([1.9999], requires_grad=True) loss = 2.652304223876886e-07\n",
            "\tgrad: 1.0 2.0 -0.00034333684295129174\n",
            "\tgrad: 2.0 4.0 -0.0013458804243686728\n",
            "\tgrad: 3.0 6.0 -0.0027859724784420337\n",
            "progress: 31 w = tensor([1.9999], requires_grad=True) loss = 1.4497023661932608e-07\n",
            "\tgrad: 1.0 2.0 -0.00025383304803572315\n",
            "\tgrad: 2.0 4.0 -0.0009950255483008874\n",
            "\tgrad: 3.0 6.0 -0.002059702884979586\n",
            "progress: 32 w = tensor([1.9999], requires_grad=True) loss = 7.923815569983025e-08\n",
            "\tgrad: 1.0 2.0 -0.00018766181840934593\n",
            "\tgrad: 2.0 4.0 -0.0007356343281639255\n",
            "\tgrad: 3.0 6.0 -0.001522763059300658\n",
            "progress: 33 w = tensor([1.9999], requires_grad=True) loss = 4.3310168108439185e-08\n",
            "\tgrad: 1.0 2.0 -0.00013874063429186734\n",
            "\tgrad: 2.0 4.0 -0.0005438632864240844\n",
            "\tgrad: 3.0 6.0 -0.0011257970028957232\n",
            "progress: 34 w = tensor([1.9999], requires_grad=True) loss = 2.3672568411213642e-08\n",
            "\tgrad: 1.0 2.0 -0.00010257261581969601\n",
            "\tgrad: 2.0 4.0 -0.00040208465401292415\n",
            "\tgrad: 3.0 6.0 -0.0008323152338061135\n",
            "progress: 35 w = tensor([1.9999], requires_grad=True) loss = 1.2939005311187974e-08\n",
            "\tgrad: 1.0 2.0 -7.583316574688581e-05\n",
            "\tgrad: 2.0 4.0 -0.0002972660097277924\n",
            "\tgrad: 3.0 6.0 -0.000615340640138129\n",
            "progress: 36 w = tensor([1.9999], requires_grad=True) loss = 7.072230420311602e-09\n",
            "\tgrad: 1.0 2.0 -5.606436943494941e-05\n",
            "\tgrad: 2.0 4.0 -0.00021977232818493064\n",
            "\tgrad: 3.0 6.0 -0.00045492871934627033\n",
            "progress: 37 w = tensor([1.9999], requires_grad=True) loss = 3.86555549790924e-09\n",
            "\tgrad: 1.0 2.0 -4.1449061095821804e-05\n",
            "\tgrad: 2.0 4.0 -0.00016248031949572805\n",
            "\tgrad: 3.0 6.0 -0.0003363342613589282\n",
            "progress: 38 w = tensor([1.9999], requires_grad=True) loss = 2.1128439571816407e-09\n",
            "\tgrad: 1.0 2.0 -3.0643788257123106e-05\n",
            "\tgrad: 2.0 4.0 -0.00012012364996749625\n",
            "\tgrad: 3.0 6.0 -0.0002486559554313317\n",
            "progress: 39 w = tensor([1.9999], requires_grad=True) loss = 1.1548429688436976e-09\n",
            "\tgrad: 1.0 2.0 -2.2655320384146194e-05\n",
            "\tgrad: 2.0 4.0 -8.880885590656362e-05\n",
            "\tgrad: 3.0 6.0 -0.00018383433172530772\n",
            "progress: 40 w = tensor([1.9999], requires_grad=True) loss = 6.312166490699508e-10\n",
            "\tgrad: 1.0 2.0 -1.674935022366597e-05\n",
            "\tgrad: 2.0 4.0 -6.565745287723246e-05\n",
            "\tgrad: 3.0 6.0 -0.0001359109274563508\n",
            "progress: 41 w = tensor([1.9999], requires_grad=True) loss = 3.4501180576914077e-10\n",
            "\tgrad: 1.0 2.0 -1.2382995612902903e-05\n",
            "\tgrad: 2.0 4.0 -4.854134280307676e-05\n",
            "\tgrad: 3.0 6.0 -0.00010048057960077017\n",
            "progress: 42 w = tensor([1.9999], requires_grad=True) loss = 1.885773233430059e-10\n",
            "\tgrad: 1.0 2.0 -9.154897252727778e-06\n",
            "\tgrad: 2.0 4.0 -3.5887197229911294e-05\n",
            "\tgrad: 3.0 6.0 -7.428649826479727e-05\n",
            "progress: 43 w = tensor([1.9999], requires_grad=True) loss = 1.0307301454830819e-10\n",
            "\tgrad: 1.0 2.0 -6.768325397477071e-06\n",
            "\tgrad: 2.0 4.0 -2.6531835558785133e-05\n",
            "\tgrad: 3.0 6.0 -5.492089960945634e-05\n",
            "progress: 44 w = tensor([1.9999], requires_grad=True) loss = 5.6337878490333887e-11\n",
            "\tgrad: 1.0 2.0 -5.00390418656238e-06\n",
            "\tgrad: 2.0 4.0 -1.9615304411857437e-05\n",
            "\tgrad: 3.0 6.0 -4.0603680135475884e-05\n",
            "progress: 45 w = tensor([1.9999], requires_grad=True) loss = 3.0793283449727384e-11\n",
            "\tgrad: 1.0 2.0 -3.6994464123196735e-06\n",
            "\tgrad: 2.0 4.0 -1.4501829936008903e-05\n",
            "\tgrad: 3.0 6.0 -3.0018787967378557e-05\n",
            "progress: 46 w = tensor([1.9999], requires_grad=True) loss = 1.6831061643842263e-11\n",
            "\tgrad: 1.0 2.0 -2.7350451259344766e-06\n",
            "\tgrad: 2.0 4.0 -1.0721376893840784e-05\n",
            "\tgrad: 3.0 6.0 -2.2193250170943202e-05\n",
            "progress: 47 w = tensor([1.9999], requires_grad=True) loss = 9.199559262725205e-12\n",
            "\tgrad: 1.0 2.0 -2.022051682093462e-06\n",
            "\tgrad: 2.0 4.0 -7.926442593841898e-06\n",
            "\tgrad: 3.0 6.0 -1.640773617239688e-05\n",
            "progress: 48 w = tensor([1.9999], requires_grad=True) loss = 5.028315648199465e-12\n",
            "\tgrad: 1.0 2.0 -1.4949270732422804e-06\n",
            "\tgrad: 2.0 4.0 -5.860114127287375e-06\n",
            "\tgrad: 3.0 6.0 -1.2130436244817133e-05\n",
            "progress: 49 w = tensor([1.9999], requires_grad=True) loss = 2.7483879946448665e-12\n",
            "\tgrad: 1.0 2.0 -1.1052175241665907e-06\n",
            "\tgrad: 2.0 4.0 -4.3324526952659426e-06\n",
            "\tgrad: 3.0 6.0 -8.968177080959094e-06\n",
            "progress: 50 w = tensor([1.9999], requires_grad=True) loss = 1.5022200500053788e-12\n",
            "\tgrad: 1.0 2.0 -8.171005783097485e-07\n",
            "\tgrad: 2.0 4.0 -3.2030342662636713e-06\n",
            "\tgrad: 3.0 6.0 -6.630280932284904e-06\n",
            "progress: 51 w = tensor([1.9999], requires_grad=True) loss = 8.210867900609599e-13\n",
            "\tgrad: 1.0 2.0 -6.040922628791634e-07\n",
            "\tgrad: 2.0 4.0 -2.368041670308685e-06\n",
            "\tgrad: 3.0 6.0 -4.901846256899489e-06\n",
            "progress: 52 w = tensor([1.9999], requires_grad=True) loss = 4.487914502671885e-13\n",
            "\tgrad: 1.0 2.0 -4.4661265885537205e-07\n",
            "\tgrad: 2.0 4.0 -1.7507216227841127e-06\n",
            "\tgrad: 3.0 6.0 -3.6239937610815787e-06\n",
            "progress: 53 w = tensor([1.9999], requires_grad=True) loss = 2.4530143392075036e-13\n",
            "\tgrad: 1.0 2.0 -3.3018609801871435e-07\n",
            "\tgrad: 2.0 4.0 -1.2943295040201974e-06\n",
            "\tgrad: 3.0 6.0 -2.6792620708704362e-06\n",
            "progress: 54 w = tensor([1.9999], requires_grad=True) loss = 1.3407740472671172e-13\n",
            "\tgrad: 1.0 2.0 -2.441105442230196e-07\n",
            "\tgrad: 2.0 4.0 -9.569133325726398e-07\n",
            "\tgrad: 3.0 6.0 -1.9808105982122015e-06\n",
            "progress: 55 w = tensor([1.9999], requires_grad=True) loss = 7.328432737799982e-14\n",
            "\tgrad: 1.0 2.0 -1.8047385452746312e-07\n",
            "\tgrad: 2.0 4.0 -7.074575094634383e-07\n",
            "\tgrad: 3.0 6.0 -1.4644370409655494e-06\n",
            "progress: 56 w = tensor([1.9999], requires_grad=True) loss = 4.0055911395594237e-14\n",
            "\tgrad: 1.0 2.0 -1.3342648630398912e-07\n",
            "\tgrad: 2.0 4.0 -5.230318258497846e-07\n",
            "\tgrad: 3.0 6.0 -1.0826758796156355e-06\n",
            "progress: 57 w = tensor([1.9999], requires_grad=True) loss = 2.1893849468352213e-14\n",
            "\tgrad: 1.0 2.0 -9.864380245971915e-08\n",
            "\tgrad: 2.0 4.0 -3.8668370549999054e-07\n",
            "\tgrad: 3.0 6.0 -8.004352700652362e-07\n",
            "progress: 58 w = tensor([1.9999], requires_grad=True) loss = 1.1966789097234508e-14\n",
            "\tgrad: 1.0 2.0 -7.292854675711169e-08\n",
            "\tgrad: 2.0 4.0 -2.858799028615522e-07\n",
            "\tgrad: 3.0 6.0 -5.917713998826457e-07\n",
            "progress: 59 w = tensor([1.9999], requires_grad=True) loss = 6.540834300926358e-15\n",
            "\tgrad: 1.0 2.0 -5.3916949571686246e-08\n",
            "\tgrad: 2.0 4.0 -2.1135444150388594e-07\n",
            "\tgrad: 3.0 6.0 -4.375036919412878e-07\n",
            "progress: 60 w = tensor([1.9999], requires_grad=True) loss = 3.575103738509694e-15\n",
            "\tgrad: 1.0 2.0 -3.986144747614162e-08\n",
            "\tgrad: 2.0 4.0 -1.5625687410647515e-07\n",
            "\tgrad: 3.0 6.0 -3.2345172940040356e-07\n",
            "progress: 61 w = tensor([1.9999], requires_grad=True) loss = 1.9540881983949486e-15\n",
            "\tgrad: 1.0 2.0 -2.947004640319051e-08\n",
            "\tgrad: 2.0 4.0 -1.1552258172287111e-07\n",
            "\tgrad: 3.0 6.0 -2.3913174374001755e-07\n",
            "progress: 62 w = tensor([1.9999], requires_grad=True) loss = 1.0680698877398007e-15\n",
            "\tgrad: 1.0 2.0 -2.17875588681693e-08\n",
            "\tgrad: 2.0 4.0 -8.540723150929352e-08\n",
            "\tgrad: 3.0 6.0 -1.7679296959727253e-07\n",
            "progress: 63 w = tensor([1.9999], requires_grad=True) loss = 5.837880138872702e-16\n",
            "\tgrad: 1.0 2.0 -1.610780353544783e-08\n",
            "\tgrad: 2.0 4.0 -6.314258982342835e-08\n",
            "\tgrad: 3.0 6.0 -1.307051640253576e-07\n",
            "progress: 64 w = tensor([1.9999], requires_grad=True) loss = 3.1908816402817204e-16\n",
            "\tgrad: 1.0 2.0 -1.19086926986256e-08\n",
            "\tgrad: 2.0 4.0 -4.668207509439526e-08\n",
            "\tgrad: 3.0 6.0 -9.663189715070075e-08\n",
            "progress: 65 w = tensor([1.9999], requires_grad=True) loss = 1.7440790940787547e-16\n",
            "\tgrad: 1.0 2.0 -8.804239115534074e-09\n",
            "\tgrad: 2.0 4.0 -3.451261676445938e-08\n",
            "\tgrad: 3.0 6.0 -7.144111435763989e-08\n",
            "progress: 66 w = tensor([1.9999], requires_grad=True) loss = 9.532826078921691e-17\n",
            "\tgrad: 1.0 2.0 -6.509079497618586e-09\n",
            "\tgrad: 2.0 4.0 -2.5515591417502037e-08\n",
            "\tgrad: 3.0 6.0 -5.281727588624108e-08\n",
            "progress: 67 w = tensor([1.9999], requires_grad=True) loss = 5.210473581538333e-17\n",
            "\tgrad: 1.0 2.0 -4.812240383955668e-09\n",
            "\tgrad: 2.0 4.0 -1.8863982376160493e-08\n",
            "\tgrad: 3.0 6.0 -3.9048444477884914e-08\n",
            "progress: 68 w = tensor([1.9999], requires_grad=True) loss = 2.847951339548937e-17\n",
            "\tgrad: 1.0 2.0 -3.5577469859049415e-09\n",
            "\tgrad: 2.0 4.0 -1.3946367616313182e-08\n",
            "\tgrad: 3.0 6.0 -2.8868981871710275e-08\n",
            "progress: 69 w = tensor([1.9999], requires_grad=True) loss = 1.5566394970966993e-17\n",
            "\tgrad: 1.0 2.0 -2.6302848787906896e-09\n",
            "\tgrad: 2.0 4.0 -1.0310717613037923e-08\n",
            "\tgrad: 3.0 6.0 -2.13431885498494e-08\n",
            "progress: 70 w = tensor([1.9999], requires_grad=True) loss = 8.508318883498459e-18\n",
            "\tgrad: 1.0 2.0 -1.9446013688195762e-09\n",
            "\tgrad: 2.0 4.0 -7.62283747235415e-09\n",
            "\tgrad: 3.0 6.0 -1.577927122298206e-08\n",
            "progress: 71 w = tensor([1.9999], requires_grad=True) loss = 4.65049550953127e-18\n",
            "\tgrad: 1.0 2.0 -1.4376673185267919e-09\n",
            "\tgrad: 2.0 4.0 -5.6356554978265194e-09\n",
            "\tgrad: 3.0 6.0 -1.1665809651617565e-08\n",
            "progress: 72 w = tensor([1.9999], requires_grad=True) loss = 2.5418796569250772e-18\n",
            "\tgrad: 1.0 2.0 -1.0628848912119793e-09\n",
            "\tgrad: 2.0 4.0 -4.166508915659506e-09\n",
            "\tgrad: 3.0 6.0 -8.62467430806646e-09\n",
            "progress: 73 w = tensor([1.9999], requires_grad=True) loss = 1.3893457917338661e-18\n",
            "\tgrad: 1.0 2.0 -7.8580342233181e-10\n",
            "\tgrad: 2.0 4.0 -3.0803501971377045e-09\n",
            "\tgrad: 3.0 6.0 -6.3763234692260085e-09\n",
            "progress: 74 w = tensor([1.9999], requires_grad=True) loss = 7.593918612610482e-19\n",
            "\tgrad: 1.0 2.0 -5.809539516121731e-10\n",
            "\tgrad: 2.0 4.0 -2.2773392061026243e-09\n",
            "\tgrad: 3.0 6.0 -4.714095780400385e-09\n",
            "progress: 75 w = tensor([1.9999], requires_grad=True) loss = 4.1507063404479805e-19\n",
            "\tgrad: 1.0 2.0 -4.2950620837700626e-10\n",
            "\tgrad: 2.0 4.0 -1.683664763163506e-09\n",
            "\tgrad: 3.0 6.0 -3.4851854735507004e-09\n",
            "progress: 76 w = tensor([1.9999], requires_grad=True) loss = 2.2687004457239367e-19\n",
            "\tgrad: 1.0 2.0 -3.1753888407592967e-10\n",
            "\tgrad: 2.0 4.0 -1.2447518571434557e-09\n",
            "\tgrad: 3.0 6.0 -2.5766375699731725e-09\n",
            "progress: 77 w = tensor([1.9999], requires_grad=True) loss = 1.2400295917242407e-19\n",
            "\tgrad: 1.0 2.0 -2.3476021127066815e-10\n",
            "\tgrad: 2.0 4.0 -9.202594242196938e-10\n",
            "\tgrad: 3.0 6.0 -1.904934876506559e-09\n",
            "progress: 78 w = tensor([1.9999], requires_grad=True) loss = 6.777747899029211e-20\n",
            "\tgrad: 1.0 2.0 -1.7356072135044087e-10\n",
            "\tgrad: 2.0 4.0 -6.803588803450111e-10\n",
            "\tgrad: 3.0 6.0 -1.4083401111975036e-09\n",
            "progress: 79 w = tensor([1.9999], requires_grad=True) loss = 3.704608385587085e-20\n",
            "\tgrad: 1.0 2.0 -1.2831558038328694e-10\n",
            "\tgrad: 2.0 4.0 -5.029967553582537e-10\n",
            "\tgrad: 3.0 6.0 -1.0412044559870992e-09\n",
            "progress: 80 w = tensor([1.9999], requires_grad=True) loss = 2.0248643722788175e-20\n",
            "\tgrad: 1.0 2.0 -9.486500474054083e-11\n",
            "\tgrad: 2.0 4.0 -3.7187142254424543e-10\n",
            "\tgrad: 3.0 6.0 -7.697735782130621e-10\n",
            "progress: 81 w = tensor([1.9999], requires_grad=True) loss = 1.1067475380419555e-20\n",
            "\tgrad: 1.0 2.0 -7.013456482241054e-11\n",
            "\tgrad: 2.0 4.0 -2.7492674803397676e-10\n",
            "\tgrad: 3.0 6.0 -5.690967697091764e-10\n",
            "progress: 82 w = tensor([1.9999], requires_grad=True) loss = 6.0491073980633274e-21\n",
            "\tgrad: 1.0 2.0 -5.185096796367361e-11\n",
            "\tgrad: 2.0 4.0 -2.0325607863469486e-10\n",
            "\tgrad: 3.0 6.0 -4.207407755529857e-10\n",
            "progress: 83 w = tensor([1.9999], requires_grad=True) loss = 3.3064292954583665e-21\n",
            "\tgrad: 1.0 2.0 -3.8334224683467255e-11\n",
            "\tgrad: 2.0 4.0 -1.502709068290642e-10\n",
            "\tgrad: 3.0 6.0 -3.1105784614737786e-10\n",
            "progress: 84 w = tensor([1.9999], requires_grad=True) loss = 1.8072507484219486e-21\n",
            "\tgrad: 1.0 2.0 -2.8340885194211296e-11\n",
            "\tgrad: 2.0 4.0 -1.1109690944977046e-10\n",
            "\tgrad: 3.0 6.0 -2.2997070914243523e-10\n",
            "progress: 85 w = tensor([1.9999], requires_grad=True) loss = 9.877871676742455e-22\n",
            "\tgrad: 1.0 2.0 -2.0953017099145654e-11\n",
            "\tgrad: 2.0 4.0 -8.213518754018878e-11\n",
            "\tgrad: 3.0 6.0 -1.7001866581267677e-10\n",
            "progress: 86 w = tensor([1.9999], requires_grad=True) loss = 5.399360390605824e-22\n",
            "\tgrad: 1.0 2.0 -1.5490719817989884e-11\n",
            "\tgrad: 2.0 4.0 -6.072298219805816e-11\n",
            "\tgrad: 3.0 6.0 -1.2569678631280112e-10\n",
            "progress: 87 w = tensor([1.9999], requires_grad=True) loss = 2.9509257592955914e-22\n",
            "\tgrad: 1.0 2.0 -1.1452172543613415e-11\n",
            "\tgrad: 2.0 4.0 -4.489209004532313e-11\n",
            "\tgrad: 3.0 6.0 -9.29283316963847e-11\n",
            "progress: 88 w = tensor([1.9999], requires_grad=True) loss = 1.612916058756163e-22\n",
            "\tgrad: 1.0 2.0 -8.466560785791444e-12\n",
            "\tgrad: 2.0 4.0 -3.318945118735428e-11\n",
            "\tgrad: 3.0 6.0 -6.870237712064409e-11\n",
            "progress: 89 w = tensor([1.9999], requires_grad=True) loss = 8.81520830581243e-23\n",
            "\tgrad: 1.0 2.0 -6.2594374128366326e-12\n",
            "\tgrad: 2.0 4.0 -2.453681702263566e-11\n",
            "\tgrad: 3.0 6.0 -5.079137110897136e-11\n",
            "progress: 90 w = tensor([1.9999], requires_grad=True) loss = 4.819139910398126e-23\n",
            "\tgrad: 1.0 2.0 -4.6278536558475025e-12\n",
            "\tgrad: 2.0 4.0 -1.8141932400794758e-11\n",
            "\tgrad: 3.0 6.0 -3.7553959941760695e-11\n",
            "progress: 91 w = tensor([1.9999], requires_grad=True) loss = 2.63454622227822e-23\n",
            "\tgrad: 1.0 2.0 -3.4217073618947325e-12\n",
            "\tgrad: 2.0 4.0 -1.3413270494311291e-11\n",
            "\tgrad: 3.0 6.0 -2.7764457399825915e-11\n",
            "progress: 92 w = tensor([1.9999], requires_grad=True) loss = 1.4403439714944095e-23\n",
            "\tgrad: 1.0 2.0 -2.5299762285158067e-12\n",
            "\tgrad: 2.0 4.0 -9.917400234371598e-12\n",
            "\tgrad: 3.0 6.0 -2.0527579636109294e-11\n",
            "progress: 93 w = tensor([1.9999], requires_grad=True) loss = 7.872264643114844e-24\n",
            "\tgrad: 1.0 2.0 -1.8705037518884637e-12\n",
            "\tgrad: 2.0 4.0 -7.332801033044234e-12\n",
            "\tgrad: 3.0 6.0 -1.517719283583574e-11\n",
            "progress: 94 w = tensor([1.9999], requires_grad=True) loss = 4.3047319182569184e-24\n",
            "\tgrad: 1.0 2.0 -1.382893799473095e-12\n",
            "\tgrad: 2.0 4.0 -5.4214410738495644e-12\n",
            "\tgrad: 3.0 6.0 -1.1223022511330782e-11\n",
            "progress: 95 w = tensor([1.9999], requires_grad=True) loss = 2.352800526787919e-24\n",
            "\tgrad: 1.0 2.0 -1.0227374502846942e-12\n",
            "\tgrad: 2.0 4.0 -4.009237386526365e-12\n",
            "\tgrad: 3.0 6.0 -8.29736279683857e-12\n",
            "progress: 96 w = tensor([1.9999], requires_grad=True) loss = 1.2844043932191261e-24\n",
            "\tgrad: 1.0 2.0 -7.558398351648066e-13\n",
            "\tgrad: 2.0 4.0 -2.9629632081196178e-12\n",
            "\tgrad: 3.0 6.0 -6.133760166449065e-12\n",
            "progress: 97 w = tensor([1.9999], requires_grad=True) loss = 7.029823516350316e-25\n",
            "\tgrad: 1.0 2.0 -5.591083152012288e-13\n",
            "\tgrad: 2.0 4.0 -2.192024339819909e-12\n",
            "\tgrad: 3.0 6.0 -4.5350390109888394e-12\n",
            "progress: 98 w = tensor([1.9999], requires_grad=True) loss = 3.8433618846729784e-25\n",
            "\tgrad: 1.0 2.0 -4.134470543704083e-13\n",
            "\tgrad: 2.0 4.0 -1.6200374375330284e-12\n",
            "\tgrad: 3.0 6.0 -3.3519853559482726e-12\n",
            "progress: 99 w = tensor([1.9999], requires_grad=True) loss = 2.100389491805257e-25\n",
            "predict (after training) 4 7.999999999999389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-RovbNZ3qHQ"
      },
      "source": [
        "# Exercise 4-4: Compute gradients using computational graph(manually)\n",
        "\n",
        "w_1 = Variable(torch.Tensor([1.0]), requires_grad=True)\n",
        "w_2 = Variable(torch.Tensor([1.0]), requires_grad=True)\n",
        "b = Variable(torch.Tensor([1.0]), requires_grad=True)\n",
        "\n",
        "def forward_2(x):\n",
        "  return x * x * w_2 + x * w_1 + b\n",
        "\n",
        "def loss_2(x, y):\n",
        "  y_pred = forward_2(x)\n",
        "  return (y_pred - y) * (y_pred - y)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUwEDaVk5eZD"
      },
      "source": [
        "x_data_2 = [1.0, 2.0, 3.0, 4.0]\n",
        "y_data_2 = [6.0, 11.0, 18.0, 27.0]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcxwbFYe5VFP",
        "outputId": "18e6f913-d7e3-41ac-84da-23e5b4c72285"
      },
      "source": [
        "# Whyrano???????\n",
        "for epoch in range(100):\n",
        "  for x_val, y_val in zip(x_data_2, y_data_2):\n",
        "    l = loss_2(x_val, y_val)\n",
        "    l.backward()\n",
        "    w_1.data = w_1.data - 0.01 * w_1.grad.data\n",
        "    w_2.data = w_2.data - 0.01 * w_2.grad.data\n",
        "    b.data = b.data - 0.01 * b.grad.data\n",
        "    w_1.grad.data.zero_()\n",
        "    w_2.grad.data.zero_()\n",
        "    b.grad.data.zero_()\n",
        "  print(\"progress:\", epoch, l.data[0])\n",
        "\n",
        "print(\"predict (after training)\", 5, forward_2(5).data[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress: 0 tensor(16.5662)\n",
            "progress: 1 tensor(89.8425)\n",
            "progress: 2 tensor(408.7866)\n",
            "progress: 3 tensor(1726.4839)\n",
            "progress: 4 tensor(7043.9146)\n",
            "progress: 5 tensor(28262.5312)\n",
            "progress: 6 tensor(112469.3906)\n",
            "progress: 7 tensor(445738.7812)\n",
            "progress: 8 tensor(1762944.)\n",
            "progress: 9 tensor(6965492.5000)\n",
            "progress: 10 tensor(27506926.)\n",
            "progress: 11 tensor(1.0860e+08)\n",
            "progress: 12 tensor(4.2869e+08)\n",
            "progress: 13 tensor(1.6921e+09)\n",
            "progress: 14 tensor(6.6790e+09)\n",
            "progress: 15 tensor(2.6362e+10)\n",
            "progress: 16 tensor(1.0405e+11)\n",
            "progress: 17 tensor(4.1070e+11)\n",
            "progress: 18 tensor(1.6210e+12)\n",
            "progress: 19 tensor(6.3981e+12)\n",
            "progress: 20 tensor(2.5253e+13)\n",
            "progress: 21 tensor(9.9674e+13)\n",
            "progress: 22 tensor(3.9341e+14)\n",
            "progress: 23 tensor(1.5528e+15)\n",
            "progress: 24 tensor(6.1288e+15)\n",
            "progress: 25 tensor(2.4190e+16)\n",
            "progress: 26 tensor(9.5479e+16)\n",
            "progress: 27 tensor(3.7685e+17)\n",
            "progress: 28 tensor(1.4874e+18)\n",
            "progress: 29 tensor(5.8709e+18)\n",
            "progress: 30 tensor(2.3172e+19)\n",
            "progress: 31 tensor(9.1460e+19)\n",
            "progress: 32 tensor(3.6099e+20)\n",
            "progress: 33 tensor(1.4248e+21)\n",
            "progress: 34 tensor(5.6238e+21)\n",
            "progress: 35 tensor(2.2197e+22)\n",
            "progress: 36 tensor(8.7611e+22)\n",
            "progress: 37 tensor(3.4580e+23)\n",
            "progress: 38 tensor(1.3649e+24)\n",
            "progress: 39 tensor(5.3871e+24)\n",
            "progress: 40 tensor(2.1263e+25)\n",
            "progress: 41 tensor(8.3923e+25)\n",
            "progress: 42 tensor(3.3124e+26)\n",
            "progress: 43 tensor(1.3074e+27)\n",
            "progress: 44 tensor(5.1603e+27)\n",
            "progress: 45 tensor(2.0368e+28)\n",
            "progress: 46 tensor(8.0391e+28)\n",
            "progress: 47 tensor(3.1730e+29)\n",
            "progress: 48 tensor(1.2524e+30)\n",
            "progress: 49 tensor(4.9431e+30)\n",
            "progress: 50 tensor(1.9510e+31)\n",
            "progress: 51 tensor(7.7007e+31)\n",
            "progress: 52 tensor(3.0395e+32)\n",
            "progress: 53 tensor(1.1997e+33)\n",
            "progress: 54 tensor(4.7351e+33)\n",
            "progress: 55 tensor(1.8689e+34)\n",
            "progress: 56 tensor(7.3766e+34)\n",
            "progress: 57 tensor(2.9115e+35)\n",
            "progress: 58 tensor(1.1492e+36)\n",
            "progress: 59 tensor(4.5358e+36)\n",
            "progress: 60 tensor(1.7903e+37)\n",
            "progress: 61 tensor(7.0661e+37)\n",
            "progress: 62 tensor(2.7890e+38)\n",
            "progress: 63 tensor(inf)\n",
            "progress: 64 tensor(inf)\n",
            "progress: 65 tensor(inf)\n",
            "progress: 66 tensor(inf)\n",
            "progress: 67 tensor(inf)\n",
            "progress: 68 tensor(inf)\n",
            "progress: 69 tensor(inf)\n",
            "progress: 70 tensor(inf)\n",
            "progress: 71 tensor(inf)\n",
            "progress: 72 tensor(inf)\n",
            "progress: 73 tensor(inf)\n",
            "progress: 74 tensor(inf)\n",
            "progress: 75 tensor(inf)\n",
            "progress: 76 tensor(inf)\n",
            "progress: 77 tensor(inf)\n",
            "progress: 78 tensor(inf)\n",
            "progress: 79 tensor(inf)\n",
            "progress: 80 tensor(inf)\n",
            "progress: 81 tensor(inf)\n",
            "progress: 82 tensor(inf)\n",
            "progress: 83 tensor(inf)\n",
            "progress: 84 tensor(inf)\n",
            "progress: 85 tensor(inf)\n",
            "progress: 86 tensor(inf)\n",
            "progress: 87 tensor(inf)\n",
            "progress: 88 tensor(inf)\n",
            "progress: 89 tensor(inf)\n",
            "progress: 90 tensor(inf)\n",
            "progress: 91 tensor(inf)\n",
            "progress: 92 tensor(inf)\n",
            "progress: 93 tensor(inf)\n",
            "progress: 94 tensor(inf)\n",
            "progress: 95 tensor(inf)\n",
            "progress: 96 tensor(inf)\n",
            "progress: 97 tensor(inf)\n",
            "progress: 98 tensor(inf)\n",
            "progress: 99 tensor(inf)\n",
            "predict (after training) 5 tensor(-1.2470e+31)\n"
          ]
        }
      ]
    }
  ]
}