{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_12_RNN1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNooEDNWbZdWPgArWncpLdl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mori8/NLP-Pytorch-practice/blob/main/pytorch_lecture/Chapter_12_RNN1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgguFmLb3Lp_"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import sys"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbZFUigluTol"
      },
      "source": [
        "idx2char = ['h', 'i', 'e', 'l', 'o']\n",
        "\n",
        "x_data = [0, 1, 0, 2, 3, 3]   # hihell\n",
        "one_hot_lookup = [[1, 0, 0, 0, 0],  # 0\n",
        "                  [0, 1, 0, 0, 0],  # 1\n",
        "                  [0, 0, 1, 0, 0],  # 2\n",
        "                  [0, 0, 0, 1, 0],  # 3\n",
        "                  [0, 0, 0, 0, 1]]  # 4\n",
        "\n",
        "y_data = [1, 0, 2, 3, 3, 4]    # ihello\n",
        "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
        "\n",
        "inputs = Variable(torch.Tensor(x_one_hot))\n",
        "labels = Variable(torch.LongTensor(y_data))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3QD3h3D3HO0"
      },
      "source": [
        "num_classes = 5\n",
        "input_size = 5      # one-hot size\n",
        "hidden_size = 5     # output from the LSTM. 5 to directly predict one-hot\n",
        "batch_size = 1      # one sentence\n",
        "sequence_length = 1 # Let's do one by one\n",
        "num_layers = 1      # one-layer RNN"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ0YMZxu3b5b"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
        "  \n",
        "  def forward(self, hidden, x):\n",
        "    # Reshape input in (batch_size, sequence_length, input_size)\n",
        "    x = x.view(batch_size, sequence_length, input_size)\n",
        "    \n",
        "    # Propagate input through RNN\n",
        "    # Input: (batch, seq_len, input_size)\n",
        "    # Hidden: (num_layers * num_directions, batch, hidden_size)\n",
        "    out, hidden = self.rnn(x, hidden)\n",
        "    out = out.view(-1, num_classes)  # To compute Loss\n",
        "    return hidden, out\n",
        "  \n",
        "  def init_hidden(self):\n",
        "    # Initialize hidden and cell states\n",
        "    # (num_layers * num_directions, batch, hidden_size)\n",
        "    return Variable(torch.zeros(num_layers, batch_size, hidden_size))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWKb7pef6CcQ",
        "outputId": "0228e462-0949-4ab6-a4ca-39a15c881405"
      },
      "source": [
        "model = Model()\n",
        "print(model)\n",
        "\n",
        "# Set loss and optimizer function\n",
        "# CrossEntropyLoss = LogSoftmax + NLLLoss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    loss = 0\n",
        "    hidden = model.init_hidden()\n",
        "\n",
        "    sys.stdout.write(\"predicted string: \")\n",
        "    for input, label in zip(inputs, labels):\n",
        "        # print(input.size(), label.size())\n",
        "        hidden, output = model(hidden, input)\n",
        "        val, idx = output.max(1)\n",
        "        sys.stdout.write(idx2char[idx.data[0]])\n",
        "        loss += criterion(output, torch.LongTensor([label]))\n",
        "\n",
        "    print(\", epoch: %d, loss: %1.3f\" % (epoch + 1, loss))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(\"Learning finished!\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (rnn): RNN(5, 5, batch_first=True)\n",
            ")\n",
            "predicted string: iiiiii, epoch: 1, loss: 10.793\n",
            "predicted string: llliii, epoch: 2, loss: 9.333\n",
            "predicted string: llllil, epoch: 3, loss: 8.436\n",
            "predicted string: llello, epoch: 4, loss: 7.637\n",
            "predicted string: llello, epoch: 5, loss: 6.934\n",
            "predicted string: llello, epoch: 6, loss: 6.316\n",
            "predicted string: llello, epoch: 7, loss: 5.749\n",
            "predicted string: ilello, epoch: 8, loss: 5.266\n",
            "predicted string: ilello, epoch: 9, loss: 4.875\n",
            "predicted string: ilello, epoch: 10, loss: 4.582\n",
            "predicted string: ilello, epoch: 11, loss: 4.363\n",
            "predicted string: ihello, epoch: 12, loss: 4.178\n",
            "predicted string: ihello, epoch: 13, loss: 4.008\n",
            "predicted string: ihello, epoch: 14, loss: 3.861\n",
            "predicted string: ihello, epoch: 15, loss: 3.741\n",
            "predicted string: ihello, epoch: 16, loss: 3.663\n",
            "predicted string: ihello, epoch: 17, loss: 3.591\n",
            "predicted string: ihello, epoch: 18, loss: 3.494\n",
            "predicted string: ihello, epoch: 19, loss: 3.391\n",
            "predicted string: ihello, epoch: 20, loss: 3.279\n",
            "predicted string: ihello, epoch: 21, loss: 3.180\n",
            "predicted string: ihello, epoch: 22, loss: 3.110\n",
            "predicted string: ihello, epoch: 23, loss: 3.059\n",
            "predicted string: ihello, epoch: 24, loss: 3.037\n",
            "predicted string: ihello, epoch: 25, loss: 2.997\n",
            "predicted string: ihello, epoch: 26, loss: 2.976\n",
            "predicted string: ihello, epoch: 27, loss: 2.954\n",
            "predicted string: ihello, epoch: 28, loss: 2.935\n",
            "predicted string: ihello, epoch: 29, loss: 2.923\n",
            "predicted string: ihello, epoch: 30, loss: 2.909\n",
            "predicted string: ihello, epoch: 31, loss: 2.901\n",
            "predicted string: ihello, epoch: 32, loss: 2.888\n",
            "predicted string: ihello, epoch: 33, loss: 2.882\n",
            "predicted string: ihello, epoch: 34, loss: 2.870\n",
            "predicted string: ihello, epoch: 35, loss: 2.866\n",
            "predicted string: ihello, epoch: 36, loss: 2.855\n",
            "predicted string: ihello, epoch: 37, loss: 2.851\n",
            "predicted string: ihello, epoch: 38, loss: 2.842\n",
            "predicted string: ihello, epoch: 39, loss: 2.838\n",
            "predicted string: ihello, epoch: 40, loss: 2.831\n",
            "predicted string: ihello, epoch: 41, loss: 2.827\n",
            "predicted string: ihello, epoch: 42, loss: 2.821\n",
            "predicted string: ihello, epoch: 43, loss: 2.817\n",
            "predicted string: ihello, epoch: 44, loss: 2.812\n",
            "predicted string: ihello, epoch: 45, loss: 2.809\n",
            "predicted string: ihello, epoch: 46, loss: 2.805\n",
            "predicted string: ihello, epoch: 47, loss: 2.802\n",
            "predicted string: ihello, epoch: 48, loss: 2.799\n",
            "predicted string: ihello, epoch: 49, loss: 2.796\n",
            "predicted string: ihello, epoch: 50, loss: 2.794\n",
            "predicted string: ihello, epoch: 51, loss: 2.791\n",
            "predicted string: ihello, epoch: 52, loss: 2.789\n",
            "predicted string: ihello, epoch: 53, loss: 2.786\n",
            "predicted string: ihello, epoch: 54, loss: 2.784\n",
            "predicted string: ihello, epoch: 55, loss: 2.782\n",
            "predicted string: ihello, epoch: 56, loss: 2.780\n",
            "predicted string: ihello, epoch: 57, loss: 2.779\n",
            "predicted string: ihello, epoch: 58, loss: 2.777\n",
            "predicted string: ihello, epoch: 59, loss: 2.775\n",
            "predicted string: ihello, epoch: 60, loss: 2.774\n",
            "predicted string: ihello, epoch: 61, loss: 2.772\n",
            "predicted string: ihello, epoch: 62, loss: 2.771\n",
            "predicted string: ihello, epoch: 63, loss: 2.769\n",
            "predicted string: ihello, epoch: 64, loss: 2.768\n",
            "predicted string: ihello, epoch: 65, loss: 2.767\n",
            "predicted string: ihello, epoch: 66, loss: 2.766\n",
            "predicted string: ihello, epoch: 67, loss: 2.765\n",
            "predicted string: ihello, epoch: 68, loss: 2.763\n",
            "predicted string: ihello, epoch: 69, loss: 2.763\n",
            "predicted string: ihello, epoch: 70, loss: 2.761\n",
            "predicted string: ihello, epoch: 71, loss: 2.760\n",
            "predicted string: ihello, epoch: 72, loss: 2.759\n",
            "predicted string: ihello, epoch: 73, loss: 2.758\n",
            "predicted string: ihello, epoch: 74, loss: 2.757\n",
            "predicted string: ihello, epoch: 75, loss: 2.757\n",
            "predicted string: ihello, epoch: 76, loss: 2.756\n",
            "predicted string: ihello, epoch: 77, loss: 2.755\n",
            "predicted string: ihello, epoch: 78, loss: 2.754\n",
            "predicted string: ihello, epoch: 79, loss: 2.753\n",
            "predicted string: ihello, epoch: 80, loss: 2.752\n",
            "predicted string: ihello, epoch: 81, loss: 2.751\n",
            "predicted string: ihello, epoch: 82, loss: 2.751\n",
            "predicted string: ihello, epoch: 83, loss: 2.750\n",
            "predicted string: ihello, epoch: 84, loss: 2.749\n",
            "predicted string: ihello, epoch: 85, loss: 2.748\n",
            "predicted string: ihello, epoch: 86, loss: 2.748\n",
            "predicted string: ihello, epoch: 87, loss: 2.747\n",
            "predicted string: ihello, epoch: 88, loss: 2.746\n",
            "predicted string: ihello, epoch: 89, loss: 2.745\n",
            "predicted string: ihello, epoch: 90, loss: 2.745\n",
            "predicted string: ihello, epoch: 91, loss: 2.744\n",
            "predicted string: ihello, epoch: 92, loss: 2.743\n",
            "predicted string: ihello, epoch: 93, loss: 2.743\n",
            "predicted string: ihello, epoch: 94, loss: 2.742\n",
            "predicted string: ihello, epoch: 95, loss: 2.741\n",
            "predicted string: ihello, epoch: 96, loss: 2.741\n",
            "predicted string: ihello, epoch: 97, loss: 2.740\n",
            "predicted string: ihello, epoch: 98, loss: 2.740\n",
            "predicted string: ihello, epoch: 99, loss: 2.739\n",
            "predicted string: ihello, epoch: 100, loss: 2.738\n",
            "Learning finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbAw2m8_-qg5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}