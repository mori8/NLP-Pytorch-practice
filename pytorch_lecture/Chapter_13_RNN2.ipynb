{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_13_RNN2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPoeWcnLMlZ3L1IfL7jdDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mori8/NLP-Pytorch-practice/blob/main/pytorch_lecture/Chapter_13_RNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi8W08sFfXMt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIcgCSlIZLaH"
      },
      "source": [
        "HIDDEN_SIZE = 100\n",
        "N_CHARS = 128\n",
        "N_CLASSES = 18"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqExvK9-fjoz"
      },
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "    super(RNNClassifier, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.n_layers = n_layers\n",
        "    # https://wikidocs.net/64779\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "  \n",
        "  def forward(self, input):\n",
        "    # input = B x S. size(0) = B\n",
        "    batch_size = input.size(0)\n",
        "\n",
        "    # input: B x S -- (transpose) --> S x B\n",
        "    input = input.t()\n",
        "\n",
        "    # Embedding S x B -> S x B x I (embedding size)\n",
        "    print(\" input\", input.size())\n",
        "    embedded = self.embedding(input)\n",
        "    print(\" embedding\", embedded.size())\n",
        "\n",
        "    # Make a hidden\n",
        "    hidden = self._init_hidden(batch_size)\n",
        "    output, hidden = self.gru(embedded, hidden)\n",
        "    print(\" gru hidden output\", hidden.size())\n",
        "    # GRU의 \"마지막 cell의 hidden output\"이 fc의 input\n",
        "    fc_output = self.fc(hidden)\n",
        "    # GRU의 output은 모든 cell의 output을 담고 있음\n",
        "    print(\" fc output\", fc_output.size())\n",
        "    return fc_output\n",
        "  \n",
        "  def _init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
        "    return Variable(hidden)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf76UM3KYBtK"
      },
      "source": [
        "def str2ascii_arr(name):\n",
        "  arr = [ord(c) for c in name]\n",
        "  return arr, len(arr)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbzhc4x2Zdsf"
      },
      "source": [
        "# Zero Padding\n",
        "# 각 시퀀스와 가장 긴 시퀀스 길이의 차이만큼 생기는 공백을 0으로 채워 단어의 끝을 의미하도록 하는 방법\n",
        "# 'adylov' = [97, 100, 121, 108, 111, 118], 'san' = [115, 97, 110]\n",
        "# => 'adylov' = [97, 100, 121, 108, 111, 118], 'san' = [115, 97, 110, 0, 0, 0]\n",
        "# Zero Padding이 된 vector를 임베딩해서 사용\n",
        "\n",
        "def pad_sequences(vectorized_seqs, seq_lengths):\n",
        "  seq_tensor = torch.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
        "  for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
        "    seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
        "  return seq_tensor"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iakngEqDb51i"
      },
      "source": [
        "# Create necessary variables, lengths, and target\n",
        "def make_variables(names):\n",
        "  sequence_and_length = [str2ascii_arr(name) for name in names]\n",
        "  vectorized_seqs = [sl[0] for sl in sequence_and_length]\n",
        "  seq_lengths = torch.LongTensor([sl[1] for sl in sequence_and_length])\n",
        "  return pad_sequences(vectorized_seqs, seq_lengths)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMZNMWnzamqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2814c5-c7f3-4369-de44-8c51899c19f7"
      },
      "source": [
        "# RNN Classification\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  names = ['adylov', 'solan', 'harb', 'san']\n",
        "  classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_CLASSES)\n",
        "\n",
        "  # for name in names:\n",
        "  #   arr, _ = str2ascii_arr(name)\n",
        "  #   inp = Variable(torch.LongTensor([arr]))\n",
        "  #   out = classifier(inp)\n",
        "  #   print(\"in\", inp.size(), \"outM\", out.size())\n",
        "  #   # in torch.Size([1, 6]) out torch.Size([1, 1, 18])(분류 결과)\n",
        "  #   # in torch.Size([1, 5]) out torch.Size([1, 1, 18])\n",
        "\n",
        "  inputs = make_variables(names)\n",
        "  out = classifier(inputs)\n",
        "  print(\"batch in\", inputs.size(), \"batch out\", out.size())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " input torch.Size([6, 4])\n",
            " embedding torch.Size([6, 4, 100])\n",
            " gru hidden output torch.Size([1, 4, 100])\n",
            " fc output torch.Size([1, 4, 18])\n",
            "batch in torch.Size([4, 6]) batch out torch.Size([1, 4, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Nv6p5AjvBg"
      },
      "source": [
        "- packed sequence: https://github.com/hunkim/PyTorchZeroToAll/blob/master/13_4_pack_pad.py\n",
        "- 참고: https://simonjisu.github.io/nlp/2018/07/05/packedsequence.html"
      ]
    }
  ]
}