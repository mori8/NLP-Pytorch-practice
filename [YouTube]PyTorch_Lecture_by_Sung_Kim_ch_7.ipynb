{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[YouTube]PyTorch_Lecture_by_Sung_Kim_ch_7.ipynb",
      "provenance": [],
      "mount_file_id": "1D322hTXkdQi_c_QvpDc_WE0IfuuOgO6t",
      "authorship_tag": "ABX9TyO+UZMmZTBKn1R/PJfAbc/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mori8/NLP-Pytorch-practice/blob/main/%5BYouTube%5DPyTorch_Lecture_by_Sung_Kim_ch_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hceWmQ6imWmH"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6ELeX1DmwgI"
      },
      "source": [
        "xy = np.loadtxt('/content/drive/MyDrive/NLP-Pytorch/data/diabetes.csv', delimiter=',', dtype=np.float32)\n",
        "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
        "y_data = Variable(torch.from_numpy(xy[:, [-1]]))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmqNzTiKnHX5"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.l1 = torch.nn.Linear(8, 6)\n",
        "    self.l2 = torch.nn.Linear(6, 4)\n",
        "    self.l3 = torch.nn.Linear(4, 2)\n",
        "    self.l4 = torch.nn.Linear(2, 1)\n",
        "\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.sigmoid = torch.nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out1 = self.relu(self.l1(x))\n",
        "    out2 = self.relu(self.l2(out1))\n",
        "    out3 = self.relu(self.l3(out2))\n",
        "    y_pred = self.sigmoid(self.l4(out3))\n",
        "    return y_pred"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "825eAq9jz74L"
      },
      "source": [
        "# exercise 7-1, 데이터셋이 작아서 그런지? loss 차이가 크게 없다\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.l1 = torch.nn.Linear(8, 10)\n",
        "    self.l2 = torch.nn.Linear(10, 12)\n",
        "    self.l3 = torch.nn.Linear(12, 14)\n",
        "    self.l4 = torch.nn.Linear(14, 16)\n",
        "    self.l5 = torch.nn.Linear(16, 18)\n",
        "    self.l6 = torch.nn.Linear(18, 14)\n",
        "    self.l7 = torch.nn.Linear(14, 12)\n",
        "    self.l8 = torch.nn.Linear(12, 8)\n",
        "    self.l9 = torch.nn.Linear(8, 4)\n",
        "    self.l10 = torch.nn.Linear(4, 1)\n",
        "\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.sigmoid = torch.nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out1 = self.relu(self.l1(x))\n",
        "    out2 = self.relu(self.l2(out1))\n",
        "    out3 = self.relu(self.l3(out2))\n",
        "    out4 = self.relu(self.l4(out3))\n",
        "    out5 = self.relu(self.l5(out4))\n",
        "    out6 = self.relu(self.l6(out5))\n",
        "    out7 = self.relu(self.l7(out6))\n",
        "    out8 = self.relu(self.l8(out7))\n",
        "    out9 = self.relu(self.l9(out8))\n",
        "    y_pred = self.sigmoid(self.l10(out9))\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX3PkY-NnmsR",
        "outputId": "13ee5fdc-845f-49f0-8390-ebc32a154453"
      },
      "source": [
        "model = Model()\n",
        "\n",
        "criterion = torch.nn.BCELoss(size_average=True)\n",
        "# SGD -> Adam\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzGxcZOOtV_u",
        "outputId": "ab0fbb85-7cde-4526-c644-86a55c062a2e"
      },
      "source": [
        "for epoch in range(100):\n",
        "  y_pred = model(x_data)\n",
        "  loss = criterion(y_pred, y_data)\n",
        "  print(epoch, loss.data.item())\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.731696367263794\n",
            "1 0.6544519662857056\n",
            "2 0.6144277453422546\n",
            "3 0.6468101143836975\n",
            "4 0.6013316512107849\n",
            "5 0.5693076252937317\n",
            "6 0.5808022022247314\n",
            "7 0.5614550709724426\n",
            "8 0.5325382351875305\n",
            "9 0.5262601375579834\n",
            "10 0.5311710834503174\n",
            "11 0.5253509879112244\n",
            "12 0.5123848915100098\n",
            "13 0.5061722993850708\n",
            "14 0.5083991885185242\n",
            "15 0.5107459425926208\n",
            "16 0.5021898150444031\n",
            "17 0.4943234920501709\n",
            "18 0.49659642577171326\n",
            "19 0.498625248670578\n",
            "20 0.49047574400901794\n",
            "21 0.48723992705345154\n",
            "22 0.4908747971057892\n",
            "23 0.4886890649795532\n",
            "24 0.48327726125717163\n",
            "25 0.48374634981155396\n",
            "26 0.48471301794052124\n",
            "27 0.48166707158088684\n",
            "28 0.4798778295516968\n",
            "29 0.4817376136779785\n",
            "30 0.4816459119319916\n",
            "31 0.47827398777008057\n",
            "32 0.47634923458099365\n",
            "33 0.47636428475379944\n",
            "34 0.4762433171272278\n",
            "35 0.4739094376564026\n",
            "36 0.4720459282398224\n",
            "37 0.4722435474395752\n",
            "38 0.47221705317497253\n",
            "39 0.470291405916214\n",
            "40 0.4683293402194977\n",
            "41 0.46767720580101013\n",
            "42 0.4669182598590851\n",
            "43 0.4648042321205139\n",
            "44 0.46335700154304504\n",
            "45 0.4630276560783386\n",
            "46 0.46231546998023987\n",
            "47 0.46067193150520325\n",
            "48 0.4601043462753296\n",
            "49 0.4602639377117157\n",
            "50 0.45930784940719604\n",
            "51 0.4582991898059845\n",
            "52 0.4579782485961914\n",
            "53 0.45733916759490967\n",
            "54 0.45648321509361267\n",
            "55 0.45627591013908386\n",
            "56 0.4559551477432251\n",
            "57 0.45513859391212463\n",
            "58 0.4546942114830017\n",
            "59 0.45436009764671326\n",
            "60 0.45364436507225037\n",
            "61 0.4532725512981415\n",
            "62 0.4530796408653259\n",
            "63 0.4524851441383362\n",
            "64 0.45195090770721436\n",
            "65 0.4514220058917999\n",
            "66 0.45074233412742615\n",
            "67 0.4502803087234497\n",
            "68 0.44979605078697205\n",
            "69 0.4492925703525543\n",
            "70 0.44898200035095215\n",
            "71 0.4486048221588135\n",
            "72 0.44828882813453674\n",
            "73 0.44808024168014526\n",
            "74 0.44776037335395813\n",
            "75 0.4473978579044342\n",
            "76 0.44710150361061096\n",
            "77 0.4467451870441437\n",
            "78 0.44649070501327515\n",
            "79 0.44622448086738586\n",
            "80 0.4459191560745239\n",
            "81 0.44561049342155457\n",
            "82 0.4452046751976013\n",
            "83 0.44483309984207153\n",
            "84 0.4444095194339752\n",
            "85 0.44395825266838074\n",
            "86 0.443451464176178\n",
            "87 0.4427209496498108\n",
            "88 0.44200044870376587\n",
            "89 0.4413161873817444\n",
            "90 0.4405244290828705\n",
            "91 0.43993067741394043\n",
            "92 0.4392353594303131\n",
            "93 0.4386769235134125\n",
            "94 0.4382596015930176\n",
            "95 0.4377948045730591\n",
            "96 0.43724972009658813\n",
            "97 0.4369584918022156\n",
            "98 0.4364878833293915\n",
            "99 0.43624868988990784\n"
          ]
        }
      ]
    }
  ]
}